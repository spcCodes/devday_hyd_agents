{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28039328",
   "metadata": {},
   "source": [
    "## Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181d96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph , START , END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage , AIMessage , SystemMessage\n",
    "from typing import TypedDict , Annotated\n",
    "from pydantic import BaseModel , Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea7fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e634d",
   "metadata": {},
   "source": [
    "## Part 1: Understanding pydantic validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da45e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Country(BaseModel):\n",
    "\n",
    "    \"\"\"Information about a country\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"name of the country\")\n",
    "    animal: str = Field(description=\"National animal of the country\")\n",
    "    capital: str = Field(description=\"Capital of the country\")\n",
    " \n",
    "structured_llm = model.with_structured_output(Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f28e9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='India', animal='Bengal Tiger', capital='New Delhi')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(\"what is the capital of india and animal of india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ef4041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='India' animal='Bengal Tiger' capital='New Delhi'\n"
     ]
    }
   ],
   "source": [
    "response = structured_llm.invoke(\"what is the capital of india and langugae of india\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f2951",
   "metadata": {},
   "source": [
    "## Part 2 : Validation using TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00fd247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't cats play poker in the jungle?\",\n",
       " 'punchline': 'Too many cheetahs!',\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Optional\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = model.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f6707",
   "metadata": {},
   "source": [
    "## sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d24792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages :Annotated[list , add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78169bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_from_llm(state:State):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\" : [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97721dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"llm\" , response_from_llm)\n",
    "\n",
    "workflow.add_edge(START , \"llm\")\n",
    "workflow.add_edge(\"llm\" , END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f9a4069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is langgraph?', additional_kwargs={}, response_metadata={}, id='ba2bfc7f-3415-4df9-a619-27a34231f47e'),\n",
       "  AIMessage(content='LangGraph is a framework or tool designed to facilitate the creation, visualization, and management of language models and natural language processing (NLP) workflows using graph-based representations. It allows users to build complex language processing pipelines by connecting various components (such as tokenizers, parsers, transformers, and other NLP modules) as nodes in a graph, enabling more intuitive design, debugging, and optimization of language-related tasks.\\n\\nBy representing language models and their operations as graphs, LangGraph helps in understanding the flow of data and transformations applied at each step, making it easier to customize and extend NLP applications. This approach is particularly useful for researchers and developers working on modular and interpretable language systems.\\n\\nIf you have a specific context or implementation of LangGraph in mind, please provide more details!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 156, 'prompt_tokens': 12, 'total_tokens': 168, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6f2eabb9a5', 'id': 'chatcmpl-BzGcrjkNQyBVjexZpGhmiSkQVipTL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--50bcf911-9cd4-4e21-95c9-07d19afb1507-0', usage_metadata={'input_tokens': 12, 'output_tokens': 156, 'total_tokens': 168, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "app.invoke({\"messages\" : \"what is langgraph?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f12db8",
   "metadata": {},
   "source": [
    "## Part 3: using Pydantic validations in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04fe223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the state\n",
    "class GraphState(TypedDict):\n",
    "    messages : Annotated[list, add_messages]\n",
    "    code_content : Annotated[str, None]\n",
    "    quality_score : Annotated[int, None]\n",
    "    num_words : Annotated[int, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13ed194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e15283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining class\n",
    "class GenerateCode(BaseModel):\n",
    "    \"\"\" \n",
    "    Extract the generated code and the num of words in the code\n",
    "    \"\"\"\n",
    "    code : str = Field(description=\"Generated software code\")\n",
    "    num_words : int = Field(description=\"Number of words in the generated code\")\n",
    "\n",
    "developer_structured_llm = model.with_structured_output(GenerateCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b5b2562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateCode(BaseModel):\n",
    "    \"\"\"\n",
    "    Evaluate the generated code and return the quality score and comments\n",
    "    \"\"\"\n",
    "    comments : str = Field(description=\"Comments on the quality score\")\n",
    "    quality_score : int = Field(description=\"Quality score of the generated code between 0 and 100\")\n",
    "\n",
    "evaluator_structured_llm = model.with_structured_output(EvaluateCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c261cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes definition\n",
    "\n",
    "#set the initial state\n",
    "def init(state):\n",
    "    print(\"----------- Init node ------------\")\n",
    "    print(\"State: \", state)\n",
    "    return {\n",
    "        \"messages\": [] , \n",
    "        \"quality_score\": 0 , \n",
    "        \"num_words\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78f8b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "developer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a software developer. You are given a task to generate a software code.\n",
    "You will be given a task and you will need to generate a software code for the task.\n",
    "Respond in json format with the following keys:\n",
    "code: The generated software code\n",
    "num_words: The number of words in the generated code\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "#creating chain\n",
    "developer_chain = developer_prompt | developer_structured_llm\n",
    "\n",
    "#create a developer node \n",
    "def generate_code(state):\n",
    "    developer_output = developer_chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    print(\"Code generated by developer: \", developer_output.code)\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=developer_output.code)] , \n",
    "        \"num_words\": developer_output.num_words,\n",
    "        \"code_content\": developer_output.code\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a high standard code reviewer. You will be given a code and you will need to evaluate the code and return the quality score and comments.\n",
    "The quality score should be between 0 and 100.\n",
    "Assess the structure , code quality and documentation of the code.\n",
    "Respond in json format with the following keys:\n",
    "comments: Comments on the quality score\n",
    "quality_score: Quality score of the generated code between 0 and 100\n",
    "            \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "evaluator_chain = evaluator_prompt | evaluator_structured_llm\n",
    "\n",
    "#create a evaluator node \n",
    "def evaluate_code(state):\n",
    "    evaluator_output = evaluator_chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    print(\"Code evaluated by evaluator: \", evaluator_output.comments)\n",
    "    return {\n",
    "        \"comments\": evaluator_output.comments , \n",
    "        \"quality_score\": evaluator_output.quality_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05ba12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(state):\n",
    "    print(\"----------- Summary node ------------\")\n",
    "    print(\"Summary: \", state)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04cfd32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Init node ------------\n",
      "State:  {'messages': [HumanMessage(content='write a python program to sort the numbers using merge sort', additional_kwargs={}, response_metadata={}, id='9fdbc74a-f6c0-49e5-b402-5e4ffb72f7ae')]}\n",
      "Code generated by developer:  def merge_sort(arr):\n",
      "    if len(arr) > 1:\n",
      "        mid = len(arr) // 2\n",
      "        left_half = arr[:mid]\n",
      "        right_half = arr[mid:]\n",
      "\n",
      "        merge_sort(left_half)\n",
      "        merge_sort(right_half)\n",
      "\n",
      "        i = j = k = 0\n",
      "\n",
      "        while i < len(left_half) and j < len(right_half):\n",
      "            if left_half[i] < right_half[j]:\n",
      "                arr[k] = left_half[i]\n",
      "                i += 1\n",
      "            else:\n",
      "                arr[k] = right_half[j]\n",
      "                j += 1\n",
      "            k += 1\n",
      "\n",
      "        while i < len(left_half):\n",
      "            arr[k] = left_half[i]\n",
      "            i += 1\n",
      "            k += 1\n",
      "\n",
      "        while j < len(right_half):\n",
      "            arr[k] = right_half[j]\n",
      "            j += 1\n",
      "            k += 1\n",
      "\n",
      "# Example usage\n",
      "numbers = [38, 27, 43, 3, 9, 82, 10]\n",
      "merge_sort(numbers)\n",
      "print(\"Sorted array is:\", numbers)\n",
      "Code evaluated by evaluator:  The code correctly implements the merge sort algorithm with a clear and standard approach. The function is well-structured, using recursion and merging sorted halves properly. Variable names are meaningful and the code is easy to follow. However, the code lacks inline comments explaining the steps, and there is no function-level docstring describing the purpose and parameters of the function. The example usage is helpful for demonstration but could be separated from the function definition for better modularity. Overall, the code is functional and clean but could be improved with better documentation and slight modularization.\n",
      "----------- Summary node ------------\n",
      "Summary:  {'messages': [HumanMessage(content='write a python program to sort the numbers using merge sort', additional_kwargs={}, response_metadata={}, id='9fdbc74a-f6c0-49e5-b402-5e4ffb72f7ae'), AIMessage(content='def merge_sort(arr):\\n    if len(arr) > 1:\\n        mid = len(arr) // 2\\n        left_half = arr[:mid]\\n        right_half = arr[mid:]\\n\\n        merge_sort(left_half)\\n        merge_sort(right_half)\\n\\n        i = j = k = 0\\n\\n        while i < len(left_half) and j < len(right_half):\\n            if left_half[i] < right_half[j]:\\n                arr[k] = left_half[i]\\n                i += 1\\n            else:\\n                arr[k] = right_half[j]\\n                j += 1\\n            k += 1\\n\\n        while i < len(left_half):\\n            arr[k] = left_half[i]\\n            i += 1\\n            k += 1\\n\\n        while j < len(right_half):\\n            arr[k] = right_half[j]\\n            j += 1\\n            k += 1\\n\\n# Example usage\\nnumbers = [38, 27, 43, 3, 9, 82, 10]\\nmerge_sort(numbers)\\nprint(\"Sorted array is:\", numbers)', additional_kwargs={}, response_metadata={}, id='14e91ffe-361d-40f0-8594-51c293b98c71')], 'code_content': 'def merge_sort(arr):\\n    if len(arr) > 1:\\n        mid = len(arr) // 2\\n        left_half = arr[:mid]\\n        right_half = arr[mid:]\\n\\n        merge_sort(left_half)\\n        merge_sort(right_half)\\n\\n        i = j = k = 0\\n\\n        while i < len(left_half) and j < len(right_half):\\n            if left_half[i] < right_half[j]:\\n                arr[k] = left_half[i]\\n                i += 1\\n            else:\\n                arr[k] = right_half[j]\\n                j += 1\\n            k += 1\\n\\n        while i < len(left_half):\\n            arr[k] = left_half[i]\\n            i += 1\\n            k += 1\\n\\n        while j < len(right_half):\\n            arr[k] = right_half[j]\\n            j += 1\\n            k += 1\\n\\n# Example usage\\nnumbers = [38, 27, 43, 3, 9, 82, 10]\\nmerge_sort(numbers)\\nprint(\"Sorted array is:\", numbers)', 'quality_score': 85, 'num_words': 102}\n",
      "**************************\n",
      "{\n",
      "  \"messages\": [\n",
      "    \"content='write a python program to sort the numbers using merge sort' additional_kwargs={} response_metadata={} id='9fdbc74a-f6c0-49e5-b402-5e4ffb72f7ae'\",\n",
      "    \"content='def merge_sort(arr):\\\\n    if len(arr) > 1:\\\\n        mid = len(arr) // 2\\\\n        left_half = arr[:mid]\\\\n        right_half = arr[mid:]\\\\n\\\\n        merge_sort(left_half)\\\\n        merge_sort(right_half)\\\\n\\\\n        i = j = k = 0\\\\n\\\\n        while i < len(left_half) and j < len(right_half):\\\\n            if left_half[i] < right_half[j]:\\\\n                arr[k] = left_half[i]\\\\n                i += 1\\\\n            else:\\\\n                arr[k] = right_half[j]\\\\n                j += 1\\\\n            k += 1\\\\n\\\\n        while i < len(left_half):\\\\n            arr[k] = left_half[i]\\\\n            i += 1\\\\n            k += 1\\\\n\\\\n        while j < len(right_half):\\\\n            arr[k] = right_half[j]\\\\n            j += 1\\\\n            k += 1\\\\n\\\\n# Example usage\\\\nnumbers = [38, 27, 43, 3, 9, 82, 10]\\\\nmerge_sort(numbers)\\\\nprint(\\\"Sorted array is:\\\", numbers)' additional_kwargs={} response_metadata={} id='14e91ffe-361d-40f0-8594-51c293b98c71'\"\n",
      "  ],\n",
      "  \"code_content\": \"def merge_sort(arr):\\n    if len(arr) > 1:\\n        mid = len(arr) // 2\\n        left_half = arr[:mid]\\n        right_half = arr[mid:]\\n\\n        merge_sort(left_half)\\n        merge_sort(right_half)\\n\\n        i = j = k = 0\\n\\n        while i < len(left_half) and j < len(right_half):\\n            if left_half[i] < right_half[j]:\\n                arr[k] = left_half[i]\\n                i += 1\\n            else:\\n                arr[k] = right_half[j]\\n                j += 1\\n            k += 1\\n\\n        while i < len(left_half):\\n            arr[k] = left_half[i]\\n            i += 1\\n            k += 1\\n\\n        while j < len(right_half):\\n            arr[k] = right_half[j]\\n            j += 1\\n            k += 1\\n\\n# Example usage\\nnumbers = [38, 27, 43, 3, 9, 82, 10]\\nmerge_sort(numbers)\\nprint(\\\"Sorted array is:\\\", numbers)\",\n",
      "  \"quality_score\": 85,\n",
      "  \"num_words\": 102\n",
      "}\n",
      "Result dumped to part3_pydantic_validations/result.json\n"
     ]
    }
   ],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"init\" , init)\n",
    "workflow.add_node(\"generate_code\" , generate_code)\n",
    "workflow.add_node(\"evaluate_code\" , evaluate_code)\n",
    "workflow.add_node(\"summary\" , summary)\n",
    "workflow.add_edge(START , \"init\")\n",
    "workflow.add_edge(\"init\" , \"generate_code\")\n",
    "workflow.add_edge(\"generate_code\" , \"evaluate_code\")\n",
    "workflow.add_edge(\"evaluate_code\" , \"summary\")\n",
    "workflow.add_edge(\"summary\" , END)\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    output_dir = \"part3_pydantic_validations\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter your coding task: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        result = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "        print(\"**************************\")\n",
    "        print(json.dumps(result, default=str, indent=2))\n",
    "        # Dump the result as JSON in the part3_pydantic_validations folder\n",
    "        output_path = os.path.join(output_dir, \"result.json\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(result, f, default=str, indent=2)\n",
    "        print(f\"Result dumped to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41620391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631992d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de216ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9e1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
